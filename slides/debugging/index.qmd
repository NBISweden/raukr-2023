---
title: "Debugging, Profiling, and Optimization"
author: "Marcin Kierczak"
image: "assets/featured.jpg"
format: revealjs
---

## {visibility="hidden"}

```{r}
library(tictoc)
library(DT)
library(profvis)
library(Rgraphviz)
library(proftools)
library(profr)
library(pryr)
library(microbenchmark)
library(ggplot2)
# remotes::install_github("cdeterman/gpuR")
#library(gpuR)
```

## Topics of This Presentation

<br><br>

Code:
<br>

- **Debugging** -- my code does not run.
- **Profiling** -- now it does run but... out of memory!
- **Optimization** -- making things better.

## Types of bugs
### There are different types of bugs we can introduce:

- Syntax -- `prin(var1), mean(sum(seq((x + 2) * (y - 9 * b)))`
- Arithmetic -- `x/0` (not in R, though!) `Inf/Inf`
- Type -- `mean('a')`
- Logic -- everything works and produces seemingly valid output that is WRONG!

### To avoid bugs:

- Encapsulate your code in smaller units (functions), you can test.
- Use classes and type checking.
- Test at the boundaries, e.g. loops at min and max value.
- Feed your functions with test data that should result with a known output.
- Use *antibugging*: `stopifnot(y <= 75)`

## Arithmetic bugs

```{r arithmetic_bugs} 
(vec <- seq(0.1, 0.9, by=0.1))
vec == 0.7 
vec == 0.5
(0.5 + 0.1) - 0.6
(0.7 + 0.1) - 0.8 # round((0.7 + 0.1) , digits = 2) - 0.8
```

Beware of floating point arithmetics!

```{r double_epsilon}
head(unlist(.Machine))
head(unlist(.Platform))
```

## Handling Errors

```{r error_log}
#| error: true

input <- c(1, 10, -7, -2/5, 0, 'char', 100, pi)
for (val in input) {
  (paste0('Log of ', val, 'is ', log10(val)))
}
```

One option is to use the `try` block:

```{r error_log_try}
for (val in input) {
  val <- as.numeric(val)
  try(print(paste0('Log of ', val, ' is ', log10(val))))
}
```

## Handling Errors with `tryCatch`

```{r error_log_tryCatch}
for (val in input) {
  val <- as.numeric(val)
  result <- tryCatch(log10(val), 
              warning = function(w) { print('Negative argument supplied. Negating.'); log10(-val) }, 
              error = function(e) { print('Not a number!'); NaN })
  print(paste0('Log of ', val, ' is ', result))
}
```

## Debugging -- Errors and Warnings

- An error in your code will result in a call to the `stop()` function that:
  - Breaks the execution of the program (loop, if-statemetnt, etc.)
  - Performs the action defined by the global parameter `error`.
- A warning just prints out the warning message (or reports it in another way)
- Global parameter `error` defines what R should do when an error occurs.

```{r debug_options}
#| eval: false

options(error = )
```

- You can use `simpleError()` and `simpleWarning()` to generate errors and warnings in your code:

```{r simpleErr_simmpleWarn}
f <- function(x) {
  if (x < 0) {
    x <- abs(x)
    w <- simpleWarning("Value less than 0. Taking abs(x)")
    w
  }
}
```

## Debugging -- What are my Options?

- Old-school debugging: a lot of `print` statements
  - print values of your variables at some checkpoints,
  - sometimes fine but often laborious,
  - need to remove/comment out manually after debugging.
  
- Dumping frames
  - on error, R state will be saved to a file,
  - file can be read into debugger,
  - values of all variables can be checked,
  - can debug on another machine, e.g. send dump to your colleague!

- Traceback
  - a list of the recent function calls with values of their params,

- Step-by-step debugging
  - execute code line by line within the debugger

## Option 1: Dumping Frames

```{r dump_frames}
#| error: true
options(error = quote(dump.frames("testdump", TRUE)))

f <- function(x) {
    sin(x)
}
f('test')
options(error = NULL)
load("testdump.rda")
# debugger(testdump)
```

[<tt>Message:  Error in sin(x) : non-numeric argument to mathematical function <br>
Available environments had calls: <br>
1: f("test") <br>
 <br>
Enter an environment number, or 0 to exit   <br>
Selection: 1 <br>
Browsing in the environment with call: <br>
   f("test") <br>
Called from: debugger.look(ind) <br>
Browse[1]> x <br>
[1] "test" <br>
Browse[1]>  <br>
[1] "test" <br>
Browse[1]> 
</tt>
]{.small}

Last empty line brings you back to the environments menu.

## Option 2: Traceback

```{r traceback, eval=T, echo=T, include=TRUE, error=TRUE}
f <- function(x) {
  log10(x)  
}

g <- function(x) {
  f(x)
}
g('test')
```

<tt>
> traceback()<br>
2: f(x) at #2<br>
1: g("test")<br>
</tt>

`traceback()` shows what were the function calls and what parameters were passed to them when the error occured.

## Option 3: Debug step-by-step

Let us define a new function `h(x, y)`:

```{r debug}
h <- function(x, y) { 
  f(x) 
  f(y) 
  }
```

Now, we can use `debug()` to debug the function in a step-by-step manner:

```{r debug2, echo=TRUE, eval=FALSE}
debug(h)
h('text', 7)
undebug(h)
```

## Option 3: Debug step-by-step cted.

`n` -- execute next line, `c` -- execute whole function, `q` -- quit debugger mode.

<tt>
> debug(h)<br>
> h('text', 7)<br>
debugging in: h("text", 7)<br>
debug at #1: {<br>
    f(x)<br>
    f(y)<br>
}<br>
</tt>
--
<tt>Browse[2]> x<br>
[1] "text"<br></tt>
--
<tt>Browse[2]> y<br>
[1] 7<br></tt>
--
<tt>Browse[2]> n<br>
debug at #2: f(x)<br></tt>
--
<tt>Browse[2]> x<br>
[1] "text"<br></tt>
--
<tt>Browse[2]> n<br>
Error in log10(x) : non-numeric argument to mathematical function<br>
</tt>

## Profiling -- `proc.time()`

Profiling is the process of identifying memory and time bottlenecks in your code.

```{r proc_time}
proc.time()
```

- `user time` -- CPU time charged for the execution of user instructions of the calling process, 
- `system time` -- CPU time charged for execution by the system on behalf of the calling process,
- `elapsed time` -- total CPU time elapsed for the currently running R process.

```{r proc_time_ex}
pt1 <- proc.time()
tmp <- runif(n =  10e5)
pt2 <- proc.time()
pt2 - pt1
```

## Profiling -- `system.time()`

```{r profiling_system_time}
system.time(runif(n = 10e6))
system.time(rnorm(n = 10e6))
```

An alternative approach is to use `tic` and `toc` statements from the `tictoc` package.

```{r tictoc, cache=TRUE}
library(tictoc)
tic()
tmp1 <-runif(n = 10e6)
toc()
```

## Profiling in Action

Let's see profiling in action! We will define four functions that fill a large vector in two different ways:

. . .

```{r profiling_fundef1}
fun_fill_loop1 <- function(n = 10e6, f) {
  result <- NULL
  for (i in 1:n) {
    result <- c(result, eval(call(f, 1)))
  }
  return(result)
}
```

. . .

```{r profiling_fundef2}
fun_fill_loop2 <- function(n = 10e6, f) {
  result <- vector(length = n)
  for (i in 1:n) {
    result[i] <- eval(call(f, 1))
  }
  return(result)
}
```
 
## Profiling in Action cted.

It is maybe better to use...

. . .

vectorization!

. . .

```{r profiling_fundef3}
fun_fill_vec1 <- function(n = 10e6, f) {
  result <- NULL
  result <- eval(call(f, n))
  return(result)
}
```

. . .

```{r profiling_fundef4}
fun_fill_vec2 <- function(n = 10e6, f) {
  result <- vector(length = n)
  result <- eval(call(f, n))
  return(result)
}
```

## Profiling our functions

```{r profile_loop, cache=TRUE}
system.time(fun_fill_loop1(n = 10e4, "runif")) # Loop 1
system.time(fun_fill_loop2(n = 10e4, "runif")) # Loop 2
system.time(fun_fill_vec1(n = 10e4, "runif"))  # Vectorized 1
system.time(fun_fill_vec2(n = 10e4, "runif"))  # Vectorized 2
```

The `system.time()` function is not the most accurate though. During the lab, we will experiment with package `microbenchmark`.

## More advanced profiling

We can also do a bit more advanced profiling, including the memory profiling, using, e.g. `Rprof()` function.

```{r Rprof, cache=TRUE}
#| include: false
#| eval: false

Rprof('profiler_test.out', interval = 0.01, memory.profiling = T)
for (i in 1:5) {
  result <- fun_fill_loop2(n = 10e4, "runif")
  print(result)
}
Rprof(NULL)
```

And let us summarise:

```{r summaryRprof}
summary <- summaryRprof('profiler_test.out', memory='both')
DT::datatable(summary$by.self, options=list(pageLength = 10, searching = F, info = F))
#knitr::kable(summary$by.self)
```

## Profiling -- `profr` package

There are also packages available that enable even more advanced profiling:

```{r profr_package}
#| eval: false

library(profr)
Rprof("profiler_test2.out", interval = 0.01)
tmp <- table(sort(rnorm(1e5)))
Rprof(NULL)
profile_df <- parse_rprof('profiler_test2.out')
```

This returns a table that can be visualised:

```{r}
#| include: false
# save(profile_df, file = 'profiler_test2.Rdat')
load('profiler_test2.Rdat')
```

```{r show_profr_result}
#| echo: false
datatable(profile_df, options=list(pageLength = 5, searching = F, info = F))
```

# Profiling -- `profr` package cted.

We can also plot the results using -- `proftools` package-

```{r show_profr_result_plot}
#| fig-align: center
#| fig-height: 4
#| fig-width: 4

library(Rgraphviz)
library(proftools) # depends on "graph" and "Rgraphviz" packages
profile_df2 <- readProfileData("profiler_test2.out")
plotProfileCallGraph(profile_df2, style = google.style, score = "total")
```

## Profiling with `profvis`

Yet another nice way to profile your code is by using Hadley Wickham's `profvis` package:

```{r profviz_demo}
#| eval: false

library(profvis)
profvis({fun_fill_loop2(1e4, 'runif')
  fun_fill_vec2(1e4, 'runif')
})
```

## Profiling with `profvis` cted.

```{r profviz_run}
#| echo: false

library(profvis)
profvis({fun_fill_loop2(1e4, 'runif')
  c()
})
```

## Optimizing your code

::: {.blockquote}
We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil. Yet we should not pass up our opportunities in that critical 3%. A good programmer will not be delulled into complacency by such reasoning, he will be wise to look carefully at the critical code; but only after that code has been identified.

- Donald Knuth
:::

:::: {.columns}
::: {.column="50%"}
![](assets/xkcd_automation.png){height="300px"}
[source: http://www.xkcd/com/1319]{.smaller}
:::

::: {.column="50%"}
![](assets/xkcd_is_it_worth_the_time_2x.png){height="300px"}
[source: http://www.xkcd/com/1205]{.smaller}
:::
::::

## Ways to optimize the code

- write it in a more efficient way, e.g. use vectorization or `*apply` family instead of loops etc.,
- allocating memory to avoid copy-on-modify,
- use package `BLAS` for linear algebra,
- use `bigmemory` package,
- GPU computations,
- multicore support, e.g. `multicore`, `snow`
- use `data.table` or `tibble` instead of `data.frame`

## Copy-on-modify

```{r copy_on_modify}
library(pryr)
order <- 1024
matrix_A <- matrix(rnorm(order^2), nrow = order)
matrix_B <- matrix_A
```

. . .

Check where the objects are in the memory:

. . .

```{r}
address(matrix_A)
address(matrix_B)
```

. . .

What happens if we modify a value in one of the matrices?

. . .

```{r}
matrix_B[1,1] <- 1
address(matrix_A)
address(matrix_B)
```

## Avoid copying by allocating memory

### No memory allocation

```{r noalloc_ex}
f1 <- function(to = 3, silent=F) {
  tmp <- c()
  for (i in 1:to) {
    a1 <- address(tmp)
    tmp <- c(tmp, i)
    a2 <- address(tmp)
    if(!silent) { print(paste0(a1, " --> ", a2)) } 
  }
}
f1()
```

## Avoid copying by allocating memory cted.

### With allocation

```{r alloc_ex}
f2 <- function(to = 3, silent = FALSE) {
  tmp <- vector(length = to, mode='numeric')
  for (i in 1:to) {
    a1 <- address(tmp)
    tmp[i] <- i
    a2 <- address(tmp)
    if(!silent) { print(paste0(a1, " --> ", a2)) }
  }
}
f2()
```

## Allocating memory -- benchmark.

```{r, cache=T}
#| fig-align: center
#| fig-height: 4
#| fig-width: 4

library(microbenchmark)
benchmrk <- microbenchmark(f1(to = 1e3, silent = T), 
                           f2(to = 1e3, silent = T), 
                           times = 100L)
ggplot2::autoplot(benchmrk)
```

## GPU

```{r gpu_R, cache=T}
#| eval: false

library(gpuR)
library(microbenchmark)
A = matrix(rnorm(1000^2), nrow=1000) # stored: RAM, computed: CPU
B = matrix(rnorm(1000^2), nrow=1000) 
gpuA = gpuMatrix(A, type = "float") # stored: RAM, computed: GPU
gpuB = gpuMatrix(B, type = "float")
vclA = vclMatrix(A, type = "float") # stored: GPU, computed: GPU
vclB = vclMatrix(B, type = "float")
bch <- microbenchmark(
  cpuC = A %*% B,
  gpuC = gpuA %*% gpuB,
  vclC = vclA %*% vclB, 
  times = 10L) 
```

[More on [Charles Determan's Blog](https://www.r-bloggers.com/r-gpu-programming-for-all-with-gpur/).]{.smaller}

## GPU cted.

```{r, cache=T}
#| fig-align: center
#| fig-height: 5
#| fig-width: 4
#| eval: false
ggplot2::autoplot(bch)
```

## Parallelization using package `parallel`

Easiest to paralllelize is `lapply`:

```{r parallel_lapply}
result <- lapply(1:2, function(x) { c(x, x^2, x^3) } )
result
```

```{r parallellized}
library(parallel)
num_cores <- detectCores() - 1
cl <- makeCluster(num_cores) # Init cluster
parLapply(cl, 1:2, function(x) { c(x, x^2, x^3)} )
stopCluster(cl)
```

## {background-image="../../assets/images/cover.jpg"}

### Thank you! Questions?

```{r}
#| echo: false
R.version[c("platform","os","major","minor")]
```

[2023 • [SciLifeLab](https://www.scilifelab.se/) • [NBIS](https://nbis.se/) • [RaukR](https://nbisweden.github.io/workshop-RaukR-2306/)]{.smaller}