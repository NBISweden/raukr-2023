{
  "hash": "d34763d26a92685cb9efcc869eca09cf",
  "result": {
    "markdown": "---\ntitle: \"Tidy work in Tidyverse\"\nauthor: \"Marcin Kierczak\"\ndescription: \"Tidyverse, tidy work and the modern R paradigm.\"\nimage: \"assets/featured.jpg\"\nformat: html\n---\n\n::: {.cell}\n\n:::\n\n\n::: {.callout-note}\nWelcome to the hands-on workshop \"Tidy Work in Tidyverse\". Most of the things necessary to complete the tutorials and challenges were covered in the lecture. However, sometimes the tasks require that you check the docs or search online. Not all our solutions are optimal. Let us know if you can do better or solve things in a different way. If stuck, look at hints, next google and if still stuck, turn to TA. It is a lot of material, do not feel bad if you do not solve all tasks. If you completed Challenge 3, you are good and have used the most important features of tidyverse! Good luck!\n:::\n\n## General exercises\n\nDatasets are available [here](https://www.dropbox.com/s/dxxt959g6iefeaf/tidyverse_lab_data.zip?dl=0).\n\n### Pipes\n#### Chunk 1\n\nRewrite the following code chunks as pipes (Load package `magrittr` because `tidyverse` supports only the `%>%` pipe!):\n\n```\nmy_cars <- mtcars[, c(1:4, 10)]\nmy_cars <- my_cars[my_cars$disp > mean(my_cars$disp), ]\nmy_cars <- colMeans(my_cars)\n```\n\nThis is our solution:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmtcars %>%\n  select(c(1:4, 10)) %>%\n  filter(disp > mean(disp)) %>%\n  colMeans() -> my_cars\n```\n:::\n\n\nWhat is wrong with our solution?\n\n::: {.callout-tip collapse=\"true\"}\n- It is better to have the result assigned on the left hand side: result <- expression. In this case the expression is the **whole** pipe.\n- Our 'expression -> result' is correct but can easily be missed when reading the code.\n:::\n\n#### Chunk 2\n\nThe `summary(x)` function is a bit special: when you type `summary(x)` in the console, `print` is called in an implicit way. Pipe call does not do, so you will have to invoke `print` in an explicit way. But the `%T>%` does unbranch for one call only, you will have to make printing of the `summary` a one single composed call using `{}`.\n\n```\nsummary(cars)\ncolSums(cars)\n```\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ncars %T>% {print(summary(.))} %>% colSums()\n```\n:::\n\n\n#### Chunk 3\n\nRewrite correlations to pipes.\n\n```\ncor(mtcars$gear, mtcars$mpg)\n```\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmtcars %$% cor(gear, mpg)\n```\n:::\n\n\n```\ncor(mtcars)\n```\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmtcars %>% cor()\n```\n:::\n\n\n#### Chunk 4\n\nGiven is the `dim_summary(nrows, ncols)` function which takes matrix `nrows` and `ncols` as arguments and prints this info about its dimensions:\n\n```\ndim_summary <- function(nrows, ncols) {\n  print(\n    paste0('Matrix M has: ', nrows, ' rows and ', ncols, ' columns.')\n  )\n}\n```\n\nRewrite the code chunks below as pipes:\n\n```\ndistr1 <- rnorm(16)\nM <- matrix(distr1, ncol = 4)\nplot(M)\nM <- M + sample(M)\ndim_summary(nrows = nrow(M), ncols = ncol(M))\n```\n\n```\ndistr2 <- rnorm(16)\nN <- matrix(distr2, ncol = 4)\ncolnames(N) <- (letters[1:4])\nsummary(N)\nN <- N + 0\n```\n\n```\nP <- M %x% t(N)\nheatmap(P)\ncolnames(P) <- letters[1:dim(P)[2]]\ncor(P[ ,'a'], P[ ,'i'])\n```\n\nA class of functions, called the *replacement functions* are of the form `function(arguments)<-value` and `rownames(x) <- c('a', 'b', 'c')` is a good example of a replacement function. When writing pipes, we have bear in mind that whole `function<-` is the name of the replacement function and thus we have to use it as such in the pipe.\n\n::: {.callout-tip}\nSometimes, it may not be possible to put everything into one single pipe, the results of running two or more pipes have to be used in the final pipe.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndim_summary <- function(nrows, ncols) {\n  print(paste0('Matrix M has: ', nrows, ' rows and ', ncols, ' columns.'))\n}\n\nM <- rnorm(16) %>%\n  matrix(ncol = 4) %T>%\n  plot() %>%\n  `+`(., sample(.)) %T>%\n  {dim_summary(nrow(.), ncol(.))}\n\nN <- rnorm(16) %>%\n  matrix(ncol = 4) %>%\n  `colnames<-`(letters[1:4]) %T>%\n  summary() %>% `+`(., 0)\n\nP <- M %>%\n  `%x%`(., t(N)) %T>%\n  heatmap() %>%\n  `colnames<-`(letters[1:dim(.)[2]]) %>%\n  as_data_frame() %$%\n  cor(a, i)\n```\n:::\n\n\n### Tibbles\n#### Task 1\n\n- Convert the `mtcars` dataset to a tibble `vehicles`.\n- Select the number of cylinders (`cyl`) variable using:\n  - the `[[index]]` accessor,\n  - the `[[string]]` accessor,\n  - the `$` accessor.\n- Do the same selection as above, but using pipe and placeholders (use all three ways of accessing a variable).\n- Print the tibble.\n- Print the 30 first rows of the tibble.\n- Change the default behaviour of printing a tibble so that at least 15 and at most 30 rows are printed.\n- What is the difference between the `tibble.print_max` and `dplyr.print_min`? Is there any? Test it.\n- Convert `vehicles` back to a `data.frame` called `automobiles`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# 1\nvehicles <- mtcars %>% as_tibble()\n\n# 2\nvehicles[['cyl']]\nvehicles[[2]]\nvehicles$cyl\n\n# 3\nvehicles %T>%\n  {print(.[['cyl']])} %T>%\n  {print(.[[2]])} %>%\n  .$cyl\n\n# 4\nvehicles\n\n# 5\nvehicles %>% head(n = 30)\n\n# 6\noptions(tibble.print_min = 15, tibble.print_max = 30)\n\n# 7\n# In theory there should be no difference. dplyr imports tibble from the tibble package\n# and dplyr.width, dplyr.print_min and dplyr.print_min are passed down to the tibble.\n# But test both behaviours. First with only the tibble package loaded, later with dplyr # loaded.\n\n# 8\nautomobiles <- as.data.frame(vehicles)\n```\n:::\n\n\n#### Task 2\n\nCreate the following tibble using `tribble()`:\n\n\n::: {.cell}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n| id|event   |date       |\n|--:|:-------|:----------|\n|  1|success |24-04-2017 |\n|  2|failed  |25-04-2017 |\n|  3|failed  |25-04-2017 |\n|  4|success |27-04-2017 |\n\n</div>\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntab <- tribble(\n  ~id, ~event, ~date,\n  1, 'success', '24-04-2017',\n  2, 'failed', '25-04-2017',\n  3, 'failed', '25-04-2017',\n  4, 'success', '27-04-2017'\n)\n```\n:::\n\n\n#### Task 3\n\nCompare the performance of `as.data.frame()`, `as_data_frame()` and `as_tibble()` on a\n100 x 30 matrix filled with random integers. Use package `microbenchmark`. Fill in your result [here](https://docs.google.com/spreadsheets/d/1_2tDeEkDVS06RkB437yBI1XEB5SUebtHWyxAf_aRJu4/edit#gid=99106509) in the Tidyverse Lab sheet, Tibbles -- performance.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntst <- replicate(30, sample(100), simplify = TRUE)\ncolnames(tst) = paste0(rep('col', times = dim(tst)[2]), 1:dim(tst)[2])\nmicrobenchmark::microbenchmark(\n  as.data.frame(tst),\n  as_data_frame(tst),\n  as_tibble(tst)\n)\n```\n:::\n\n\n#### Task 4\n\nDo you think tibbles are lazy? Try to create a tibble that tests whether *lazy evaluation* applies to tibbles too.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntibble(x = sample(1:10, size = 10, replace = T), y = log10(x))\n```\n:::\n\n\n### Parsing\n\nParse the following vectors using `parse_` functions:\n\n- `vec1 <- c(1, 7.2, 3.84, -5.23)` -- parse it as double (any problems? why?).\n- Now, parse the same vector `c(1, 7.2, 3.84, -5.23)` as integer. What happens?\n- Can you still parse it as integer somehow?\n- Parse as double `vec2 <- c('2', '3,45', '?', '-7,28')`\n- Parse correctly `vec3 <- c('2', '3,45', '?', '-7.28')`\n- Parse the following guessing the parser: `vec4 <- c('barrel: 432.7$', 'liter: 15.42PLN', 'gallon costs approx 32.1SEK', 'sunny, wind gusts up till 55m/s')`\n- Can you parse `vec4` as number? Do it if you can.\n- Parse `vec5 <- \"25 Dec 2015\"` as date (hint: `?parse_date()`).\n- Parse `10_Jul_1410` as date.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nvec1 <- c(1, 7.2, 3.84, -5.23)\nvec2 <- c('2', '3,45', '?', '-7,28')\nvec3 <- c('2', '3,45', '?', '-7.28')\nvec4 <- c('barrel: 432.7$', 'liter: 15.42PLN', 'gallon costs approx 32.1SEK', 'sunny, wind gusts up till 55m/s')\nvec5 <- \"25 Dec 2015\"\nparse_double(vec1)\nparse_integer(vec1)\nparse_integer(as.integer(vec1)) # Is it the best way? Hint: rounding.\nparse_double(vec2, na = '?', locale = locale(decimal_mark = ','))\nparse_number(vec2, na = '?', locale = locale(decimal_mark = ','))\nguess_parser(vec4)\nparse_guess(vec4)\n# Yes, you can:\nparse_number(vec4)\nparse_date(vec5, format=\"%d %b %Y\")\nparse_date(\"10_Jul_1410\", format=\"%d%.%b%.%Y\")\n```\n:::\n\n\n## NYC flights Challenge\n\nThe `nycflights13` package contains information about all flights that departed from NYC (i.e., EWR, JFK and LGA) in 2013: 336,776 flights with 16 variables. To help understand what causes delays, it also includes a number of other useful datasets: weather, planes, airports, airlines. We will use it to train working with tibbles and `dplyr`.\n\n### Task 1: Selecting column\n\n- Load the `nycflights13` package (install if necessary),\n- Read about the data in the package docs,\n- Inspect the `flights` tibble.\n- Select all columns but `carrier` and `arr_time`,\n- Select `carrier`, `tailnum` and `origin`,\n- Hide columns from `day` through `carrier`,\n- Select all columns that have to do with `arr`ival (hint: `?tidyselect`),\n- Select columns based on a vector `v <- c(\"arr_time\", \"sched_arr_time\", \"arr_delay\")`,\n- Rename column `dest` to `destination` using:\n  - `select()` and\n  - `rename()`\n\nWhat is the difference between the two approaches?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ninstall.packages('nycflights13')\n\nlibrary('nycflights13')\n\n?nycflights13\n\nflights\n\nflights %>% select(-carrier, -arr_time)\n\nflights %>% select(carrier, tailnum, origin)\n\nflights %>% select(-(day:carrier))\n\nflights %>% select(contains('arr_')) # or\n\nv <- c(\"arr_time\", \"sched_arr_time\", \"arr_delay\")\nflights %>% select(v) # ambiguous, or better\nflights %>% select(all_of(v))\n\nflights %>% select(destination = dest)\nflights %>% rename(destination = dest)\n# select keeps only the renamed column while rename returns the whole dataset\n# with the column renamed\n```\n:::\n\n\n### Task 2: Filtering rows\n\n- Filter only the flights that arrived ahead of schedule\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>% filter(arr_delay < 0)\n```\n:::\n\n\n- Filter the flights that had departure delay between 10 and 33\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>% filter(dep_delay >= 10, dep_delay <= 33) # or\nflights %>% filter(between(dep_delay, 10, 33))\n```\n:::\n\n\n- Fish out all flights with unknown arrival time\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>% filter(is.na(arr_time))\n```\n:::\n\n\n- Retrieve rows 1234:1258 (hint: `?slice`)\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>% slice(1234:1258)\n```\n:::\n\n\n- Sample (`?sample_n()`) 3 random flights per day in March\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnycflights13::flights %>% filter(month == 3) %>%\n  group_by(day) %>%\n  slice_sample(n = 3)\n```\n:::\n\n\n- Show 5 most departure-delayed flights in January per carrier\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnycflights13::flights %>%\n  filter(month == 1) %>%\n  group_by(carrier) %>%\n  slice_max(dep_delay, n = 5)\n```\n:::\n\n\n- Retrieve all `unique()` routes and sort them by destination\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnycflights13::flights %>%\n  select(origin, dest) %>%\n  unique() %>%\n  arrange(dest)\n\nnycflights13::flights %>%\n  mutate(route = paste(origin, dest, sep=\"-\")) %>%\n  select(route) %>%\n  unique()\n```\n:::\n\n\n- Retrieve all `distinct()` routes and sort them by destination\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nnycflights13::flights %>%\n  select(origin, dest) %>%\n  distinct() %>%\n  arrange(dest)\n# or\nflights %>%\n  mutate(route = paste(origin, dest, sep=\"-\"))  %>%\n  distinct(route)\n```\n:::\n\n\n- Is `unique()` more efficient than `distinct()`?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmicrobenchmark::microbenchmark(\n   unique = nycflights13::flights %>%\n     select(origin, dest) %>%\n     unique() %>%\n     arrange(dest),\n   distinct = nycflights13::flights %>%\n     distinct(origin, dest) %>%\n     arrange(dest),\n   times = 10L\n)\n\n# Distinct is faster.\n```\n:::\n\n\n### Task 3: Trans(mutations)\n\n- `air_time` is the amount of time in minutes spent in the air. Add a new column `air_spd` that will contain aircraft's airspeed in mph,\n- As above, but keep only the new `air_spd` variable,\n- Use `rownames_to_column()` on `mtcars` to add car model as an extra column,\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>% mutate(air_spd = distance/(air_time / 60))\nflights %>% transmute(air_spd = distance/(air_time / 60))\nmtcars %>% rownames_to_column('model')\n```\n:::\n\n\n### Task 4: Groups and counts\n\n- Use `group_by()`, `summarise()` and `n()` to see how many planes were delayed (departure) every month,\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n  filter(dep_delay > 0) %>%\n  group_by(month) %>%\n  summarise(num_dep_delayed = n())\n```\n:::\n\n\n- Do the same but using `tally()` and `count()`,\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n  filter(dep_delay > 0) %>%\n  group_by(month) %>%\n  tally()\n\nflights %>%\n  filter(dep_delay > 0) %>%\n  count(month)\n```\n:::\n\n\n- What was the mean `dep_delay` per month?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n  group_by(month) %>%\n  summarise(mean_dep_delay = mean(dep_delay, na.rm = T))\n```\n:::\n\n\n- Count the number of incoming delayed flights from each unique origin and sort origins by this count (descending),\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n  filter(arr_delay > 0) %>%\n  group_by(origin) %>%\n  summarise(cnt = n()) %>%\n  arrange(desc(cnt))\n```\n:::\n\n\n- Do the same using `tally()`\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n  filter(arr_delay > 0) %>%\n  group_by(origin) %>%\n  tally(sort = T)\n```\n:::\n\n\n- Use `summarise()` to sum total `dep_delay` per month in hours,\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n group_by(month) %>%\n summarize(tot_dep_delay = sum(dep_delay/60, na.rm = T))\n```\n:::\n\n\n- Use the `wt` parameter of `count()` (works with `tally()` too) to achieve the same,\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n group_by(month) %>%\n count(wt = dep_delay/60)\n```\n:::\n\n\n- Run `group_size()` on `carrier` what does it return?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n    group_by(carrier) %>%\n    group_size()\n```\n:::\n\n\n- Use `n_groups()` to check the number of unique origin-carrier pairs,\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nflights %>%\n    group_by(carrier) %>%\n    n_groups()\n```\n:::\n\n\n::: {.callout-tip}\n## Note on `ungroup`\nDepending on the version of `dplyr`, you may or may need to use the `ungroup()` if you want to group your data on some other variables. In the newer versions, `summarise` and `mutate` drop one aggregation level.\n\n\n```\nflights %>%\n  group_by(origin) %>%\n  mutate(mean_delay_orig = (mean(dep_delay, na.rm = T) + mean(arr_delay, na.rm = T)) / 2) %>%\n  ungroup() %>%\n  group_by(carrier) %>%\n  mutate(mean_delay_carr = (mean(dep_delay, na.rm = T) + mean(arr_delay, na.rm = T)) / 2) %>%\n  select(origin, carrier, mean_delay_orig, mean_delay_carr)\n```\n\n:::\n\n### Task 5: Joins\n\nGiven the following tibbles `set1` and `set2`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset1 <- tribble(\n  ~id, ~color,\n  'id1', 'grey',\n  'id1', 'red',\n  'id2', 'green',\n  'id3', 'blue'\n)\n\nset2 <- tribble(\n  ~id, ~size,\n  'id2', 'XL',\n  'id3', 'M',\n  'id4', 'M'\n)\n\nset1\nset2\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|id  |color |\n|:---|:-----|\n|id1 |grey  |\n|id1 |red   |\n|id2 |green |\n|id3 |blue  |\n\n</div><div class=\"kable-table\">\n\n|id  |size |\n|:---|:----|\n|id2 |XL   |\n|id3 |M    |\n|id4 |M    |\n\n</div>\n:::\n:::\n\n\nPerform joins on `id` that result in the grey area from the Venn diagrams below. We have not talked about all possible joins, so read the docs if you do not know which join to use.\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){fig-align='left' width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nleft_join(set1, set2, by = 'id')\n```\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-36-1.png){fig-align='left' width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nright_join(set1, set2, by = 'id')\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|id  |color |size |\n|:---|:-----|:----|\n|id2 |green |XL   |\n|id3 |blue  |M    |\n|id4 |NA    |M    |\n\n</div>\n:::\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-38-1.png){fig-align='left' width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ninner_join(set1, set2, by = 'id') # or\nsemi_join(set1, set2, by = 'id') # semi_join removes duplicates in x\n# and also returns only columns from x.\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|id  |color |size |\n|:---|:-----|:----|\n|id2 |green |XL   |\n|id3 |blue  |M    |\n\n</div><div class=\"kable-table\">\n\n|id  |color |\n|:---|:-----|\n|id2 |green |\n|id3 |blue  |\n\n</div>\n:::\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-40-1.png){fig-align='left' width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nfull_join(set1, set2, by = 'id') # or\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|id  |color |size |\n|:---|:-----|:----|\n|id1 |grey  |NA   |\n|id1 |red   |NA   |\n|id2 |green |XL   |\n|id3 |blue  |M    |\n|id4 |NA    |M    |\n\n</div>\n:::\n:::\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-42-1.png){fig-align='left' width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nanti_join(set1, set2, by = 'id')\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|id  |color |\n|:---|:-----|\n|id1 |grey  |\n|id1 |red   |\n\n</div>\n:::\n:::\n\n\n## Tidying data\n\nNow time to do some data tidying. First install a package with some untidy data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#renv::install(\"rstudio/EDAWR\")\nlibrary(EDAWR)\n```\n:::\n\n\n- Tidy `cases` so that years are not in separate columns, but in the column called `year` containing a value per each year.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntidy_cases <- cases %>%\n  pivot_longer(-country, names_to = \"year\", values_to = \"count\")\n```\n:::\n\n\n- Now time for the `pollution` dataset. Tidy it so that there separate columns for `large` and `small` pollution values.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntidy_pollution <- pollution %>%\n  pivot_wider(city, names_from = size, values_from = amount)\n```\n:::\n\n\n- The `storms` dataset contains the `date` column. Make it into 3 columns: `year`, `month` and `day`. Store the result as `tidy_storms`\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntidy_storms <- storms %>%\n  separate(col = date,\n           into = c(\"year\", \"month\", \"day\"),\n           sep = \"-\")\n```\n:::\n\n\n- Now, merge `year`, `month` and `day` in `tidy_storms` into a `date` column again but in the \"DD/MM/YYYY\" format.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntidy_storms %>% unite(col = \"date\", 4:6, sep = \"/\")\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|storm   | wind| pressure|date       |\n|:-------|----:|--------:|:----------|\n|Alberto |  110|     1007|2000/08/03 |\n|Alex    |   45|     1009|1998/07/27 |\n|Allison |   65|     1005|1995/06/03 |\n|Ana     |   40|     1013|1997/06/30 |\n|Arlene  |   50|     1010|1999/06/11 |\n|Arthur  |   45|     1010|1996/06/17 |\n\n</div>\n:::\n:::\n\n\n## Nanopore Channel Activity Challenge\n### Introduction\n\nYou will be given a `fastq` file coming from MinION sequencer (Oxford Nanopore). This file contains test reads from the chicken genome. The flow-cell used here has 512 channels, each channel consists of 4 pores and only one pore is active at a time. Once your sequence gets stuck for some reason, the device will attempt to remove it from the pore by playing with reversing polarity on that pore. If this was successful, the pore will be re-used. Your task will be to visualise reading events from the meta-data in the `fastq` dataset and to see how each and every channel behaved. Also, you will plot the distribution of reading times.\n\nDatasets are available [here](https://www.dropbox.com/s/dxxt959g6iefeaf/tidyverse_lab_data.zip?dl=0).\n\n### Preparations\n\nFirst, we will need to load the necessary libraries. I will give you a hint -- you need the following libraries:\n\n- `here` -- not necessary, but it is an elegant way of reading the data locally from the project folder,\n- `tidyverse` -- well, quite obvious why,\n- `ShortRead` from Bioconductor -- to deal with short reads in `fastq`,\n- `lubridate` -- to figure out reading times.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(here)\nlibrary(tidyverse)\n#BiocManager::install(\"ShortRead\")\nlibrary(ShortRead)\nlibrary(lubridate)\n```\n:::\n\n\n### Reading data\n\nNow, let's read the fastq data. Check `ShortRead` documentation to see how to read our `fastq` file. Also, try to use package `here`. If you write: `data <- here::here('data/my.fastq')`, the `my.fastq` file will be read from the `data` folder which is a sub folder of your project root, i.e. the folder where your r script is. It is a good practice and also prevents [Jenny Bryan from coming to your office and setting your computer on fire](https://www.tidyverse.org/articles/2017/12/workflow-vs-script/).\n\nNow think a bit, to plot reading events, do we need all the data in the file or only some specific part? You may want to see some few first lines of the `fastq` to learn about the data structure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_data <- here::here('labs/tidyverse/assets/FUL1_fastqs_GRID2.fastq')\nf <- ShortRead::FastqFile(raw_data)\nrfq <- ShortRead::readFastq(f)\nheaders <- rfq@id\nclose(f)\n```\n:::\n\n\n### Extracting information you need\n\nIn this step, we are extracting data from fastq headers of each and every read in the fastq file. Not super efficient and perhaps the slowest step of the whole analyses. Can you do it better than our example solution?\n\nDesired output: a table (tibble/data.frame) with reads as rows and meta-data as columns.\n\n::: {.callout-tip}\nWe will use the `stringr` package for string manipulation. Use `str_split()` to explode string data into columns and `str_remove_all()` to get rid of unwanted characters.\n\n- To split string on a particular character, group of characters use `str_split`. Here we split on comma.\n\n```\ntext <- \"This text is long, or not?\"\nstr_split(text, ',')\n```\n\n- To remove everything following a given character, e.g. comma:\n\n```\nstr_remove_all(text, \",.*\")\n```\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata <- dplyr::as_tibble(matrix(NA_character_, ncol = 6, nrow = length(headers)), .name_repair = 'minimal')\ncolnames(data) <- c('id', 'run_id', 'sample_id', 'read', 'channel', 'start_time')\nfor (i in 1:length(headers)) {\n  data[i,] <- toString(headers[[i]]) %>%\n    strsplit(' ') %>%\n    unlist() %>%\n    str_remove_all(\".*=\") %>% t()\n}\n```\n:::\n\n:::\n\n### Preparing tidy dataset\n\nNow, the fun part begins:\n\n- Add column `start_dttm` that represents start time for a given read as proper `datetime` object (read `lubridate` docs) and\n- Add column `chan` that is the proper numeric representation of the channel,\n- Group reads by channel,\n- Arrange them by time,\n- Add time to next read (NA if this was the last read) and\n- Sort by channel again.\n\n::: {.callout-tip}\nRead about `lead()`\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndata2 <- data %>%\n  mutate(start_dttm = as_datetime(start_time)) %>%\n  mutate(chan=as.numeric(channel)) %>%\n  group_by(chan) %>%\n  arrange(start_dttm) %>%\n  mutate(time_diff = lead(start_dttm) - start_dttm) %>%\n  arrange(chan)\n```\n:::\n\n\n### Plotting events per channel\n\nHere, we want to see what was happening in each channel over time. Plot the data you have just prepared so that:\n\n- Each point is the start of a new read,\n- Colour corresponds to the lag to the next read.\n\nCan you visualise this in a better way? Different geometry?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(data2, mapping = aes(x = start_dttm,\n                            y = as.factor(chan),\n                            col = as.numeric(time_diff)\n                            )\n       ) +\n  geom_point(size = .5) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_events-1.png){width=672}\n:::\n:::\n\n\n### Distribution of time intervals\n\nNow, we want to see how time-to-next-read is distributed. Since it has a veeeeery long right tail, I am cutting off everything above 200 seconds (just by eyeballing).\n\n- Plot time-to-next-read is distribution (you can use base-R `histogram`),\n- Can you find a better cutoff value?\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Show time-to-next read distribution\n# thr <- mean(data2$time_diff, na.rm = T) + 3 * sd(data2$time_diff, na.rm = T)\ntmp <- data2 %>%\n  ungroup() %>%\n  filter(time_diff < 200) %>%\n  select(time_diff)\n\nhist(as.numeric(tmp$time_diff), breaks = 1000, las=1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/time_to_next_1-1.png){width=672}\n:::\n:::\n\n\n## Species Identification Challenge\n\nIn this challenge, your task will be to analyse species composition of some samples. The samples, were actual products containing parts of plants. DNA has been isolated form the samples and an amplicon metabarcoding was performed using two sets of primers: for the ITS1 and the ITS2 region. Each sample had 3 technical replicates. Your task will be to transform BLAST output to a tidy form suitable for further analyses or visualisation.\n\n### Load necessary libraries\n\nWe will obviously need `tidyverse`, we will also do some string manipulations with `stringr` also `here` package is good to have.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(here)\n```\n:::\n\n\n### Input variables\n\nHere, we will define our input variables. We need:\n\n- `file` that contains the path to the dataset,\n- `sample_name` is a string, the name of the sample you want to analyse,\n- `threshold` is an integer saying what is a the minimal number of replicates that have to contain an OTU in order to call it a true positive (TP),\n- `strict` a logical. If set to TRUE, only the OTUs deemed TP will be shown.\n\nBelow we set some example values:\n\n\n::: {.cell}\n\n:::\n\n\n```\n# Change the path to your project path, where your data is\nfile <- here::here(\"docs/tidyverse_Marcin/lab/assets/blast_result.csv\")\nsample_name <- 'SAMPLE12'\nthreshold <- 1\nstrict <- F\n```\n\n### Reading the data\n\nNow, you should read the data:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nspecies_orig <- read_csv(file, col_names = c(\"sample\",\"its\",\"replicate\",\"OTU\",\"size\",\"hit\",\"perc_ident\",\"score\",\"family\",\"species\")) %>%\n  select(-score)\n\nhead(species_orig,n = 10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|sample   |its  |replicate |OTU  | size|hit      | perc_ident|family           |species               |\n|:--------|:----|:---------|:----|----:|:--------|----------:|:----------------|:---------------------|\n|SAMPLE10 |ITS1 |R1        |OTU1 |  372|KX522674 |      97.08|Anacardiaceae    |Spondias_tuberosa     |\n|SAMPLE10 |ITS1 |R1        |OTU1 |  372|AJ783644 |      97.53|Betulaceae       |Betula_populifolia    |\n|SAMPLE10 |ITS1 |R1        |OTU1 |  372|AJ783641 |      97.53|Betulaceae       |Betula_alnoides       |\n|SAMPLE10 |ITS1 |R1        |OTU1 |  372|MF171078 |      98.71|Pentaphylacaceae |Pentaphylax_euryoides |\n|SAMPLE10 |ITS1 |R1        |OTU2 |   14|KY214931 |      98.33|Musaceae         |Musa_ornata           |\n|SAMPLE10 |ITS1 |R1        |OTU2 |   14|KY214926 |      96.23|Musaceae         |Musa_sp.              |\n|SAMPLE10 |ITS1 |R1        |OTU2 |   14|KY214930 |      95.73|Musaceae         |Musa_basjoo           |\n|SAMPLE10 |ITS1 |R1        |OTU2 |   14|KY214927 |      97.67|Musaceae         |Musella_lasiocarpa    |\n|SAMPLE10 |ITS1 |R2        |OTU1 |  357|AM233397 |      95.62|Apocynaceae      |Secamone_filiformis   |\n|SAMPLE10 |ITS1 |R2        |OTU1 |  357|FR832858 |      96.69|Rubiaceae        |Tricalysia_perrieri   |\n\n</div>\n:::\n:::\n\n\nAs you see, the following information are included in the data:\n\n- `sample` is simply the name of the sample,\n- `its` is either ITS1 or ITS2 and tells which set of PCR primers has been used,\n- `replicate` contains information on which replicate the sequences come from,\n- `OTU` is a unique identifier of the so-called Operational Taxonomic Unit, an OTU often corresponds to one species but not always. Sometimes 2 OTUs represent the same species, sometimes 1 OTU consists of more than one species,\n- `size` is the number of reads that support that particular OTU,\n- `hit` is the BLAST hit identifier. The 4 top BLAST hits are reported per OTU,\n- `perc_identity` is the percentage identity of the sequence to the BLAST hit,\n- `family` is the identified plant family,\n- `species` is the identified plant species.\n\n### Number of replicates per species\n\nCreate a new dataset `species` that contains an extra column `n_replicates`. The column contains number of replicates this particular species is present in. Do it per sample and its.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nspecies <- species_orig %>%\n  group_by(sample, its, species) %>%\n  mutate(n_replicates = n_distinct(replicate)) %>%\n  ungroup()\n\nhead(species,n = 10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|sample   |its  |replicate |OTU  | size|hit      | perc_ident|family           |species               | n_replicates|\n|:--------|:----|:---------|:----|----:|:--------|----------:|:----------------|:---------------------|------------:|\n|SAMPLE10 |ITS1 |R1        |OTU1 |  372|KX522674 |      97.08|Anacardiaceae    |Spondias_tuberosa     |            2|\n|SAMPLE10 |ITS1 |R1        |OTU1 |  372|AJ783644 |      97.53|Betulaceae       |Betula_populifolia    |            1|\n|SAMPLE10 |ITS1 |R1        |OTU1 |  372|AJ783641 |      97.53|Betulaceae       |Betula_alnoides       |            1|\n|SAMPLE10 |ITS1 |R1        |OTU1 |  372|MF171078 |      98.71|Pentaphylacaceae |Pentaphylax_euryoides |            1|\n|SAMPLE10 |ITS1 |R1        |OTU2 |   14|KY214931 |      98.33|Musaceae         |Musa_ornata           |            1|\n|SAMPLE10 |ITS1 |R1        |OTU2 |   14|KY214926 |      96.23|Musaceae         |Musa_sp.              |            1|\n|SAMPLE10 |ITS1 |R1        |OTU2 |   14|KY214930 |      95.73|Musaceae         |Musa_basjoo           |            1|\n|SAMPLE10 |ITS1 |R1        |OTU2 |   14|KY214927 |      97.67|Musaceae         |Musella_lasiocarpa    |            1|\n|SAMPLE10 |ITS1 |R2        |OTU1 |  357|AM233397 |      95.62|Apocynaceae      |Secamone_filiformis   |            1|\n|SAMPLE10 |ITS1 |R2        |OTU1 |  357|FR832858 |      96.69|Rubiaceae        |Tricalysia_perrieri   |            1|\n\n</div>\n:::\n:::\n\n\n### Filter out unwanted samples\n\nNow, your task is to filter out all but your `sample_name` samples from the dataset.\nCall the resulting dataset `my_sample`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmy_sample <- species %>%\n  filter(sample == sample_name)\n```\n:::\n\n\n### Missing observations\n\nWhat happens if a set of primers failed to amplify or if one replicate was lost?\nUse `complete()` to make sure you have `NA` values in such cases.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmy_sample <- my_sample %>%\n  complete(its = c(\"ITS1\", \"ITS2\"),\n           replicate = c(\"R1\",\"R2\",\"R3\"))\n```\n:::\n\n\n### Sorting issue\n\nLook, the first sample in the table is `SAMPLE10`. Why not `SAMPLE1`?\nThat's a sorting issue: if sorted as character, 10 will come before 1. WE have to fix this by adding trailing zero to the values in `OTU`. We do not expect more than 99 OTUs in a sample, so it is ok with only one trailing 0 (otherwise the 100-th sample will spoil our sorting and come out like: SAMPLE100, SAMPLE01, SAMPLE10). We will need to use regular expression:\n\n- All values in the `OTU` column that follow pattern \"OTU*digit*\" we need to change to \"OTU0*digit*\". Regular expression that matches this is `OTU([0-9]$)` and it should be replaced by: `OTU0\\\\1`. Ask your TAs to explain this if you do not know much about regular expressions and pattern matching.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_sample <- my_sample %>%\n  mutate(OTU = str_replace(OTU,pattern = \"OTU([0-9]$)\",\n                          replacement = \"OTU0\\\\1\"))\nhead(my_sample,n = 10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|its  |replicate |sample   |OTU   | size|hit      | perc_ident|family          |species                 | n_replicates|\n|:----|:---------|:--------|:-----|----:|:--------|----------:|:---------------|:-----------------------|------------:|\n|ITS1 |R1        |SAMPLE12 |OTU01 | 4169|LC089998 |      99.44|Brassicaceae    |Capsella_bursa-pastoris |            3|\n|ITS1 |R1        |SAMPLE12 |OTU02 | 2686|KP794392 |      98.19|Euphorbiaceae   |Tragia_cf.              |            3|\n|ITS1 |R1        |SAMPLE12 |OTU02 | 2686|KP794390 |      98.19|Euphorbiaceae   |Tragia_chlorocaulon     |            3|\n|ITS1 |R1        |SAMPLE12 |OTU02 | 2686|KP794378 |      98.19|Euphorbiaceae   |Tragia_bahiensis        |            3|\n|ITS1 |R1        |SAMPLE12 |OTU02 | 2686|KP794320 |      98.19|Euphorbiaceae   |Bia_alienata            |            3|\n|ITS1 |R1        |SAMPLE12 |OTU04 | 1353|GQ396671 |      97.44|Euphorbiaceae   |Triadica_sebifera       |            3|\n|ITS1 |R1        |SAMPLE12 |OTU04 | 1353|KX522674 |      96.25|Anacardiaceae   |Spondias_tuberosa       |            3|\n|ITS1 |R1        |SAMPLE12 |OTU04 | 1353|KY860928 |      96.23|Adoxaceae       |Viburnum_prunifolium    |            3|\n|ITS1 |R1        |SAMPLE12 |OTU04 | 1353|KX757310 |      96.23|Caryophyllaceae |Silene_caesia           |            3|\n|ITS1 |R1        |SAMPLE12 |OTU06 |  577|KY860926 |     100.00|Asteraceae      |Taraxacum_officinale    |            3|\n\n</div>\n:::\n:::\n\n\n### Supporting reads\n\nSometimes, an OTU generates two or more top BLAST hits that come from the same species. We have decided to sum reads in such cases. Do it!\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmy_sample <- my_sample %>%\n  ungroup() %>%\n  group_by(sample, its, replicate, OTU, species, n_replicates) %>%\n  summarise(n_reads = sum(size)) %>%\n  ungroup() %>%\n  group_by(its, species, OTU)\n\nhead(my_sample,n=10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|sample   |its  |replicate |OTU   |species                 | n_replicates| n_reads|\n|:--------|:----|:---------|:-----|:-----------------------|------------:|-------:|\n|SAMPLE12 |ITS1 |R1        |OTU01 |Capsella_bursa-pastoris |            3|    4169|\n|SAMPLE12 |ITS1 |R1        |OTU02 |Bia_alienata            |            3|    2686|\n|SAMPLE12 |ITS1 |R1        |OTU02 |Tragia_bahiensis        |            3|    2686|\n|SAMPLE12 |ITS1 |R1        |OTU02 |Tragia_cf.              |            3|    2686|\n|SAMPLE12 |ITS1 |R1        |OTU02 |Tragia_chlorocaulon     |            3|    2686|\n|SAMPLE12 |ITS1 |R1        |OTU04 |Silene_caesia           |            3|    1353|\n|SAMPLE12 |ITS1 |R1        |OTU04 |Spondias_tuberosa       |            3|    1353|\n|SAMPLE12 |ITS1 |R1        |OTU04 |Triadica_sebifera       |            3|    1353|\n|SAMPLE12 |ITS1 |R1        |OTU04 |Viburnum_prunifolium    |            3|    1353|\n|SAMPLE12 |ITS1 |R1        |OTU06 |Taraxacum_amplum        |            3|     577|\n\n</div>\n:::\n:::\n\n\n### Within-OTU species diversity\n\nNow, we want to see how many identifications an OTU got. Implement this. Store the result in a new tibble `diversity`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndiversity <- my_sample %>%\n  ungroup() %>%\n  group_by(its, replicate, OTU) %>%\n  summarise(n_species = n())\n\nhead(diversity,n=10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|its  |replicate |OTU   | n_species|\n|:----|:---------|:-----|---------:|\n|ITS1 |R1        |OTU01 |         1|\n|ITS1 |R1        |OTU02 |         4|\n|ITS1 |R1        |OTU04 |         4|\n|ITS1 |R1        |OTU06 |         4|\n|ITS1 |R1        |OTU07 |         3|\n|ITS1 |R1        |OTU08 |         2|\n|ITS1 |R1        |OTU10 |         1|\n|ITS1 |R1        |OTU11 |         3|\n|ITS1 |R1        |OTU13 |         3|\n|ITS1 |R1        |OTU15 |         2|\n\n</div>\n:::\n:::\n\n\n### Adding diversity data\n\nAdd the `diversity` data to `my_sample` using appropriate `join` function. Also, remove the column with sample names since we are dealing with only one sample.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nmy_sample <- my_sample %>%\n  left_join(diversity) %>%\n  select(-sample)\n\nhead(my_sample,n=10)\n```\n\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|its  |replicate |OTU   |species                 | n_replicates| n_reads| n_species|\n|:----|:---------|:-----|:-----------------------|------------:|-------:|---------:|\n|ITS1 |R1        |OTU01 |Capsella_bursa-pastoris |            3|    4169|         1|\n|ITS1 |R1        |OTU02 |Bia_alienata            |            3|    2686|         4|\n|ITS1 |R1        |OTU02 |Tragia_bahiensis        |            3|    2686|         4|\n|ITS1 |R1        |OTU02 |Tragia_cf.              |            3|    2686|         4|\n|ITS1 |R1        |OTU02 |Tragia_chlorocaulon     |            3|    2686|         4|\n|ITS1 |R1        |OTU04 |Silene_caesia           |            3|    1353|         4|\n|ITS1 |R1        |OTU04 |Spondias_tuberosa       |            3|    1353|         4|\n|ITS1 |R1        |OTU04 |Triadica_sebifera       |            3|    1353|         4|\n|ITS1 |R1        |OTU04 |Viburnum_prunifolium    |            3|    1353|         4|\n|ITS1 |R1        |OTU06 |Taraxacum_amplum        |            3|     577|         4|\n\n</div>\n:::\n:::\n\n\n- What columns did we join on in our example solution?\n\n### Visualising the data\n\nCan you think of a good way of visualising the data? Think of:\n\n- Type of plot you want. The simpler the better?\n- Which variables you would like to visualise? We have chosen `ITS`, `replicate`, `n_reads`, `n_replicates`, `OTU`, `threshold`, `n_species` and `specie`. Well, pretty much all of them :-)\n- How do you represent variables: colours, shapes, separate plots, sizes?\n- What transformations do you need to apply before visualising the data?\n\nOur example solution involves some `ggplot2` magics. But would base-R be good enough for this type of plot?\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Red -- only one species in the current OTU, blue -- identification above the threshold, grey -- identification below the threshold](index_files/figure-html/unnamed-chunk-58-1.png){width=864}\n:::\n:::\n\n\n## Wildlife Aircraft Strikes Challenge\n\nUse the [FAA report](https://www.kaggle.com/faa/wildlife-strikes) and `tidyverse` to learn more about aircraft incidents with wildlife. Use your imagination and [NYC data science blog](https://nycdatascience.com/blog/student-works/exploring-aviation-accidents-from-1908-through-the-present/) for inspiration!\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}