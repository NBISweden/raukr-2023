{
  "hash": "12e7f7cfbb5af81d411612d35c668468",
  "result": {
    "markdown": "---\ntitle: \"tidymodels - Your data budget\"\nauthor: \"Max Kuhn\"\n\nformat:\n  revealjs:\n    slide-number: true\n    code-line-numbers: true\n    footer: <https://nbisweden.github.io/raukr-2023>\n    include-before-body: styles/header.html\n    include-after-body: styles/footer-annotations.html\n    theme: [default, styles/tidymodels.scss]\n    width: 1280\n    height: 720\nknitr:\n  opts_chunk:\n    echo: true\n    collapse: true\n    comment: \"#>\"\n    fig.align: \"center\"\n\nfig-format: svg\n---\n\n\n\n\n## The Data\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n\ntidymodels_prefer()\ntheme_set(theme_bw())\noptions(pillar.advice = FALSE, pillar.min_title_chars = Inf)\n\ndata(cells, package = \"modeldata\")\ncells$case <- NULL\n```\n:::\n\n\n\n## Data splitting and spending\n\nFor machine learning, we typically split data into training and test sets:\n\n. . .\n\n-   The **training set** is used to estimate model parameters.\n-   The **test set** is used to find an independent assessment of model performance.\n\n. . .\n\nDo not ðŸš« use the test set during training.\n\n## Data splitting and spending\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](part_2_files/figure-revealjs/unnamed-chunk-3-1.svg){fig-align='center'}\n:::\n:::\n\n\n# The more data<br>we spend ðŸ¤‘<br><br>the better estimates<br>we'll get.\n\n## Data splitting and spending\n\n-   Spending too much data in **training** prevents us from computing a good assessment of predictive **performance**.\n\n. . .\n\n-   Spending too much data in **testing** prevents us from computing a good estimate of model **parameters**.\n\n# The testing data is precious ðŸ’Ž\n\n## Data splitting and spending \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\ncell_split <- initial_split(cells)\ncell_split\n#> <Training/Testing/Total>\n#> <1514/505/2019>\n```\n:::\n\n\n\n## Accessing the data \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncell_tr <- training(cell_split)\ncell_te <- testing(cell_split)\n```\n:::\n\n\n## The training set\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncell_tr\n#> # A tibble: 1,514 Ã— 57\n#>    class angle_ch_1 area_ch_1 avg_inten_ch_1 avg_inten_ch_2 avg_inten_ch_3\n#>    <fct>      <dbl>     <int>          <dbl>          <dbl>          <dbl>\n#>  1 WS         73.1        333          213.          273.            277. \n#>  2 WS        155.         681           60.9         179.            103. \n#>  3 WS        150.         317           33.4         193.             14.9\n#>  4 WS         27.4        271          497.          316.             85.7\n#>  5 PS        160.         779           26.3          69.2            48.2\n#>  6 PS         88.1        268           34.8           4.05           79.6\n#>  7 PS         90.1        175           81.2         372.             81.5\n#>  8 PS         63.9        161           24.0          41.9            49.4\n#>  9 WS        113.         629           24.3         113.             23.5\n#> 10 WS          8.01       451           36.0         145.             63.3\n#> # â„¹ 1,504 more rows\n#> # â„¹ 51 more variables: avg_inten_ch_4 <dbl>, convex_hull_area_ratio_ch_1 <dbl>,\n#> #   convex_hull_perim_ratio_ch_1 <dbl>, diff_inten_density_ch_1 <dbl>,\n#> #   diff_inten_density_ch_3 <dbl>, diff_inten_density_ch_4 <dbl>,\n#> #   entropy_inten_ch_1 <dbl>, entropy_inten_ch_3 <dbl>,\n#> #   entropy_inten_ch_4 <dbl>, eq_circ_diam_ch_1 <dbl>,\n#> #   eq_ellipse_lwr_ch_1 <dbl>, eq_ellipse_oblate_vol_ch_1 <dbl>, â€¦\n```\n:::\n\n\n## The test set \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncell_te\n#> # A tibble: 505 Ã— 57\n#>    class angle_ch_1 area_ch_1 avg_inten_ch_1 avg_inten_ch_2 avg_inten_ch_3\n#>    <fct>      <dbl>     <int>          <dbl>          <dbl>          <dbl>\n#>  1 WS         107.        431           28.0         116.             63.9\n#>  2 WS         174.        177          260.          596.            124. \n#>  3 PS         104.        258           17.6         125.             22.5\n#>  4 PS          33.5       157          114.           37.9           269. \n#>  5 PS          80.6      1060           59.3          39.7            29.9\n#>  6 WS         124.        223          375.          293.            112. \n#>  7 PS          27.5       170           27.5           2.99           60.3\n#>  8 PS         134.        302           53.3          73.7           120. \n#>  9 PS         135.        582           29.5          38.4            56.4\n#> 10 WS         145.        277           65.9         273.             38.1\n#> # â„¹ 495 more rows\n#> # â„¹ 51 more variables: avg_inten_ch_4 <dbl>, convex_hull_area_ratio_ch_1 <dbl>,\n#> #   convex_hull_perim_ratio_ch_1 <dbl>, diff_inten_density_ch_1 <dbl>,\n#> #   diff_inten_density_ch_3 <dbl>, diff_inten_density_ch_4 <dbl>,\n#> #   entropy_inten_ch_1 <dbl>, entropy_inten_ch_3 <dbl>,\n#> #   entropy_inten_ch_4 <dbl>, eq_circ_diam_ch_1 <dbl>,\n#> #   eq_ellipse_lwr_ch_1 <dbl>, eq_ellipse_oblate_vol_ch_1 <dbl>, â€¦\n```\n:::\n\n\n\n## Data splitting and spending \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\ncell_split <- initial_split(cells, prop = 0.8)\ncell_tr <- training(cell_split)\ncell_te <- testing(cell_split)\n\nnrow(cell_tr)\nnrow(cell_te)\n#> [1] 1615\n#> [1] 404\n```\n:::\n\n\n# What about a validation set?\n\n##  {background-color=\"white\" background-image=\"https://www.tmwr.org/premade/validation.svg\" background-size=\"50%\"}\n\n:::notes\nWe will use this tomorrow\n:::\n\n##  {background-color=\"white\" background-image=\"https://www.tmwr.org/premade/validation-alt.svg\" background-size=\"40%\"}\n\n\n## Class imbalance\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(cell_tr, aes(class)) +\n  geom_bar()\n```\n\n::: {.cell-output-display}\n![](part_2_files/figure-revealjs/unnamed-chunk-9-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Split smarter\n\nWe can conduct the splitting within groups to preserve the outcome distirbtion. \n\nFor classification models, we can use the outcome as a strata. \n\nFor regression, stratified sampling would split within each quartile.\n\n\n\n## Stratification\n\nUse `strata = class`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\ncell_split <- initial_split(cells, prop = 0.8, strata = class)\ncell_split\n#> <Training/Testing/Total>\n#> <1615/404/2019>\n```\n:::\n\n\n. . .\n\nStratification often helps, with very little downside\n\n\n\n\n",
    "supporting": [
      "part_2_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}